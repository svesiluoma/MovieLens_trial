---
title: "Movielens Project"
author: "Sari Vesiluoma"
date: "1 11 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r create_d, include=FALSE}
library(tidyverse)
library(caret)
library(dslabs)

################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)

### End of the given code ###
```

## Introduction

The purpose of this project is to introduce a movie recommender based on the Movielens 10M data. The data preparation was done based on the code given in the exercice introduction. Ratings and movies were separately excerpted from the Movielens data, then combined. Then movielens data was split into two groups, one data frame called edx for training data and one data frame called validation for validation data including 10 % of the movielens data. Validation data was created so, that it included only rows where movieId and userId were also existing in the training set (edx). Rows which were excluded from the validation set were added back to the training set. 

The dimensions of the training data (edx) and validation data are

```{r dims}
dim(edx)
dim(validation)
```


## Analysis

The summary of the training set clearly shows that there are no NA values, so no need for pre-processing those in this data. So, this data can be used as is. 

```{r summary}
summary(edx)
```

Rows in the data look like this

```{r head}
edx %>% head()
```

The amount of unique movies and users in the training data are

```{r amounts}
n_distinct(edx$movieId)
n_distinct(edx$userId)
```

When using this data, it is important to recognize that the amount of ratings per movie vary hugely between the movies as shown in the histogram below.

```{r ratings_movie, echo=FALSE}
ratings <- edx %>% group_by(movieId, title) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
hist(ratings$count)
```

Also, when looking the way people have used rating levels, it is clear that they have used integer ratings much more than the half (.5) ratings as can bee seen from the line chart below. 

```{r ratings_rates, echo=FALSE}
edx %>%
  group_by(rating) %>%
  summarize(count = n()) %>%
  ggplot(aes(rating, count)) +
  geom_line()
```

The idea here is to use several different machine learning algorithms to test which one(s) might give the best result in recommending. The value of the result will be analyzed based on RMSE score of the algorithm. 

```{r rmse, results="hidden"}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings-predicted_ratings)^2))
}
```

To start with we will need a some kind of a baseline compared to which to try to improve the RMSE. For that purpose we will use the mean value of the ratings in the training set. The resulting RMSE value is

```{r average, echo=FALSE}
mu_hat <- mean(edx$rating)
naive_rmse <- RMSE(validation$rating, mu_hat)
naive_rmse
rmse_results <- data.frame(method = "Based on average", RMSE=naive_rmse)
```


## Results


## Conclusion

xxx
